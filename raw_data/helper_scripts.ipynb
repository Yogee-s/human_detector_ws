{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0e27d6",
   "metadata": {},
   "source": [
    "### Convert RealSense .bag → MP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c250cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "\n",
    "def bag_to_mp4(bag_path: str, out_path: str, fps: float = 30.0):\n",
    "    \"\"\"\n",
    "    Read a RealSense .bag file and write out a color-only MP4.\n",
    "    \"\"\"\n",
    "    pipeline = rs.pipeline()\n",
    "    cfg = rs.config()\n",
    "    cfg.enable_device_from_file(bag_path, repeat_playback=False)\n",
    "    profile = pipeline.start(cfg)\n",
    "\n",
    "    # get color stream resolution\n",
    "    color_stream = profile.get_stream(rs.stream.color).as_video_stream_profile()\n",
    "    w, h = color_stream.width(), color_stream.height()\n",
    "\n",
    "    # set up VideoWriter (mp4v codec)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            color = frames.get_color_frame()\n",
    "            if not color:\n",
    "                continue\n",
    "            # convert to numpy array (RGB)\n",
    "            img_rgb = np.asanyarray(color.get_data())\n",
    "            # convert RGB→BGR for correct colors in OpenCV\n",
    "            img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "            writer.write(img_bgr)\n",
    "    except RuntimeError:\n",
    "        # bag playback ended\n",
    "        pass\n",
    "    finally:\n",
    "        writer.release()\n",
    "        pipeline.stop()\n",
    "        print(f\"✅ Wrote {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d49f40",
   "metadata": {},
   "source": [
    "### Run conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeea2c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote /home/yogee/Desktop/human_detector_ws/training_data/raw_data/video1.mp4\n"
     ]
    }
   ],
   "source": [
    "bag_to_mp4(bag_file, output_mp4, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d2fe7",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3927a371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Copied 1324 train / 331 val images\n",
      "✅ data.yaml written to /home/yogee/Desktop/human_detector_ws/raw_data/../training_data/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# 1) (Optional) install PyYAML if you haven't already\n",
    "# !pip install pyyaml --quiet\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# 2) Define your paths (all relative to your notebook cwd == HUMAN_DETECTOR_WS)\n",
    "repo_root  = Path().resolve()\n",
    "export_dir = repo_root / \"labelled_data\" / \"Video_1\" / \"obj_train_data\"\n",
    "names_file = repo_root / \"labelled_data\" / \"Video_1\" / \"obj.names\"\n",
    "dest_dir   = repo_root / \"../training_data\"\n",
    "\n",
    "assert export_dir.exists(), f\"Export dir not found: {export_dir}\"\n",
    "assert names_file.exists(), f\"Names file not found: {names_file}\"\n",
    "\n",
    "# 3) Create train/val subfolders under training_data/images and training_data/labels\n",
    "for split in (\"train\",\"val\"):\n",
    "    (dest_dir/\"images\"/split).mkdir(parents=True, exist_ok=True)\n",
    "    (dest_dir/\"labels\"/split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4) Gather all image files from the CVAT export\n",
    "img_exts = {\".png\", \".jpg\", \".jpeg\"}\n",
    "all_imgs = sorted(p for p in export_dir.iterdir() if p.suffix.lower() in img_exts)\n",
    "\n",
    "# 5) Shuffle & split 80/20\n",
    "random.seed(42)\n",
    "random.shuffle(all_imgs)\n",
    "n_train   = int(0.8 * len(all_imgs))\n",
    "train_imgs, val_imgs = all_imgs[:n_train], all_imgs[n_train:]\n",
    "\n",
    "# 6) Copy images and their .txt labels into the training_data folder structure\n",
    "for split, imgs in [(\"train\", train_imgs), (\"val\", val_imgs)]:\n",
    "    for img_path in imgs:\n",
    "        lbl_path = export_dir / f\"{img_path.stem}.txt\"\n",
    "        if not lbl_path.exists():\n",
    "            continue\n",
    "        shutil.copy2(img_path,   dest_dir/\"images\"/split/img_path.name)\n",
    "        shutil.copy2(lbl_path,   dest_dir/\"labels\"/split/f\"{img_path.stem}.txt\")\n",
    "\n",
    "# 7) Read your class names\n",
    "with open(names_file) as f:\n",
    "    names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# 8) Write a data.yaml for YOLO training\n",
    "cfg = {\n",
    "    \"path\": str(dest_dir),     # base dir for train/val\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\":   \"images/val\",\n",
    "    \"nc\":    len(names),\n",
    "    \"names\": names\n",
    "}\n",
    "with open(dest_dir/\"data.yaml\", \"w\") as f:\n",
    "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
    "\n",
    "print(f\"✅ Copied {len(train_imgs)} train / {len(val_imgs)} val images\")\n",
    "print(f\"✅ data.yaml written to {dest_dir/'data.yaml'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
