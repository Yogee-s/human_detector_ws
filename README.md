# Human + Teleco Robot Detection

A ROS 2 + YOLOv8 pipeline for realâ€time 2D detection of **persons** and a custom **Teleco robot**, with 3D distance estimation via Intel RealSense depth data.

---

## ğŸš€ Features

- **2D Detection** of Person & Teleco robot
- **3D Distance Estimation** at each boundingâ€box center
- **ROS 2 Node** publishes annotated images on `/human_detector/annotated`
- **Custom Training** on combined COCOâ€person + Teleco datasets
- Jupyter notebooks for **data prep** & **model training**

---

## ğŸ“‚ Repository Layout

```
HUMAN_DETECTOR_WS/
â”œâ”€â”€ data_raw/                   # raw exports: ros bags, videos, CVAT/Roboflow outputs
â”‚   â”œâ”€â”€ converted_mp4_videos/
â”‚   â””â”€â”€ labelled_data/
â”œâ”€â”€ data_training/              # final train/val split for YOLO
â”‚   â”œâ”€â”€ data_person/            # COCOâ€person subset (train/val)
â”‚   â”œâ”€â”€ data_teleco/            # Teleco robot images & labels
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â”œâ”€â”€ labels/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â””â”€â”€ data.yaml               # combined config (nc:2, names:['person','teleco'])
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ human_detector_launch.py
â”œâ”€â”€ src/human_detector/
â”‚   â”œâ”€â”€ human_detection_node.py
â”‚   â””â”€â”€ human_pose_node.py      # optional poseâ€based variant
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_*.pt               # your custom weights
â”œâ”€â”€ helper_scripts.ipynb        # data prep & splitting notebooks
â”œâ”€â”€ train.ipynb                 # example Ultralytics training notebook
â”œâ”€â”€ package.xml & setup.py      # ROS 2 package metadata
â””â”€â”€ README.md                   # â† this file
```

---

## âš™ï¸ Installation

1. **Clone & build the ROS 2 workspace**

   ```bash
   git clone https://github.com/YOUR_ORG/human_detector_ws.git
   cd human_detector_ws
   colcon build --merge-install
   source install/setup.bash
   ```

2. **Install Python deps** (for notebooks & scripts)

   ```bash
   pip install ultralytics opencv-python pyrealsense2 pyyaml
   ```

---

## ğŸ“Š Data Preparation

1. **Export** frames/video from ROS-bag â†’ annotate in CVAT/Roboflow.
2. **Run** `helper_scripts.ipynb` to:

   - Collect Teleco & COCO-person exports
   - Split into `train/val` under `data_training/`
   - Generate `data_training/data.yaml`:

     ```yaml
     train: images/train
     val: images/val
     nc: 2
     names:
       - person
       - teleco
     ```

3. **Verify** `data_training/images/{train,val}` and `labels/{train,val}` exist.

---

## ğŸ¤– Model Training

### CLI

```bash
yolo train \
  data=data_training/data.yaml \
  model=yolov8n.pt \
  epochs=120 \
  imgsz=416 \
  batch=16 \
  project=runs/train \
  name=human_teleco
```

### Jupyter

In **train.ipynb**:

```python
from ultralytics import YOLO

model = YOLO('models/yolov8n.pt')  # base checkpoint
results = model.train(
    data='data_training/data.yaml',
    epochs=120,
    imgsz=416,
    batch=16,
    device=0
)
print("Best weights saved at:", results.best)
```

---

## ğŸš¨ Inference with ROS 2

Launch live detection + distance estimation:

```bash
source install/setup.bash
ros2 launch human_detector human_detector_launch.py
```

- **Input:**

  - `/camera/realsense2_camera/color/image_raw`
  - `/camera/realsense2_camera/depth/image_rect_raw`

- **Output:**

  - `/human_detector/annotated` (`sensor_msgs/Image`)

To swap models, edit the `model_path` parameter in `launch/human_detector_launch.py` to your `best_*.pt`.

---

## ğŸ–¥ Viewing Results

- An OpenCV window shows 2D boxes + distance labels.
- Alternatively, view `/human_detector/annotated` in **RViz** or **rqt_image_view**.

---

## ğŸ›  Customization

- Use `human_detection_node.py` for pure detection (no keypoints).
- Use `human_pose_node.py` if you want poseâ€keypoints.
- Adjust YOLO training parameters (augmentation, freeze layers, etc.) in `train.ipynb`.

---

## ğŸ“š Notebooks

- **helper_scripts.ipynb** â€” frame extraction, dataset merge/split, `data.yaml` generation
- **train.ipynb** â€” interactive training & metric plotting
- **inference.ipynb** â€” test detection on images/video

---

## ğŸ¤ Contributing

Contributions welcome! Please open issues or PRs for enhancements.
Released under the **MIT License**.

---

Â© 2025 Yogee-s â€” Bridging robotics with state-of-the-art vision.
